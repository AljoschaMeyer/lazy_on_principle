% https://2024.splashcon.org/track/splash-2024-Onward-papers#Call-for-Papers
% 13 Pages, excluding bibliography

\documentclass[sigplan,screen,10pt,anonymous,review]{acmart}
% \documentclass[11pt,conference]{IEEEtran}

\input{libs.tex}
\usepackage{macros}

\title{Lazy on Principle}
% \title{Principled Lazy Sequences}

\author{Aljoscha Meyer}
\affiliation{TU Berlin, Germany}
\email{research@aljoscha-meyer.de}

\begin{document}

\begin{abstract}
This is the abstract.
\end{abstract}

\maketitle

\section{Introduction}\label{introduction}

When sequences of data become too large to fit into memory at once, programs need to process them lazily. From the humble iterator to asynchronous APIs for streams and sinks with error handling and buffering, every language needs libraries for working with lazy sequences.

For such a fundamental, conceptually simple, and language-agnostic problem, one might expect a principled, unified solution that programming language designers and library authors can turn to and implement in their language of choice.

But the opposite is the case. Learning a new programming language implies learning yet another, slightly (or not so slightly) different set of APIs for working with sequences. Even within a single language, there are often competing libraries --- \cref{wtfjs} lists some thirty popular Javascript libraries alone.

Starting from ``\textit{Which} abstraction is the best?'', we quickly moved to ``\textit{Is} there a best abstraction?'', and then to the more constructive ``\textit{What} would make an abstraction the best?''. In this paper, we present our answers to these questions. In a nutshell:

\begin{enumerate}
    \item Abstractions for working with lazy sequences in the wild are ad-hoc designs.
    \item We propose a principled way of evaluating them.
    \item No prior abstractions satisfy all evaluation criteria.
    \item We develop abstractions that do.
    \item \sout{Everybody everywhere should use our abstractions without further reflection.}
\end{enumerate}

Note that we will focus on strictly evaluated languages. This makes explicit the design elements that enable laziness.

We further restrict our focus to the two simplemost ways of interacting with a (possibly infinite) sequence: \textit{consuming} a sequence item by item, or \textit{producing} a sequence item by item. Both modes of interaction are of great practical interest, they correspond, for example, to reading and writing bytes over a network. We do not consider more complex settings such as random access, or mixing reading and writing.

\subsection{Evaluating Sequence APIs}

Equipped with a vague notion of wanting to ``lazily consume or produce sequences'', how can we do better than simply trying to find a design that satisfies all use-cases we can come up with? In mathematics, one would define a set of criteria that a solution should satisfy, in a way that makes no assumptions about any possible solutions themselves.

For example, a mathematician might want to work with numbers ``with no gaps in-between'' (i.e., the real numbers). They might formalize this intuitive notion as a minimal, infinite, complete ordered field. Any candidate construction (say, the Dedekind cuts of rational numbers), can now be objectively measured against the requirements. As an added bonus, it turns out that all constructions satisfying the abstract requirements are isomorphic. Some constructions might be more convenient than others in certain settings, but ultimately, they are all interchangeable.

This approach of construction-independent axiomization is the only way we can conceive to clear the proliferation of competing library designs.

Sadly, we could not find an airtight mathematical formalism to capture our problem space. The criteria we now present leave gaps that must be filled by argumentation rather than proof, the API design still remains part art as much as science. This makes the following paragraphs the weakest link of this paper. We nevertheless think that both our approach and the designs it yields are novel --- and useful.

The criteria by which we shall evaluate lazy sequence abstractions are minimality, symmetry, and expressivity.

\textbf{Minimality} asks that no aspect of the API design can be expressed through other aspects of the design. Removing any feature impacts what can be expressed.

% \textbf{Universality} asks that the same fundamental design works irrespective of whether processing is synchronous or asynchronous, buffered or unbuffered, etc. We want a solution that is applicable indepedently of such implementation details.

\textbf{Symmetry} asks that reading and writing data should be dual. The two intuitive notions of producing and consuming a sequence item by item are fully symmetric and sit on the same level of abstraction. Any API design that introduces an imbalance between the two must either be contaminated with incidental complexity, or it must be missing functionality for one of the two access modes.

\textbf{Expressivity} asks that the API design is powerful enough to get the job done, but also no more powerful than necessary. This is by far the most vague of our criteria, because we cannot simply equate more expressivity with a better design. We \textit{can}, however, draw on the theory of formal languages to categorize the classes of sequences whose consumption of production can be described by an API. Some of these classes are more natural candidates than others.

Of these criteria, minimality is arguably the least controversial. Symmetry turns out to be the one we generally find the most neglected in the wild, and strict adherence to symmetry shapes the designs we propose to differ significantly from any others we are aware of. Expressivity might have the weakest definition, but turns out to be rather unproblematic: real-world constraints on the APIs lead to a level of expressivity that also has a convincing formal counterpart --- the $\omega$-regular languages (see \cref{showing_expressivity} for details) --- making us quite confident about the appropriate level of expressivity.

TODO argue for *consistency* as a cure to the painfulness of building async stuff

To obtain a first indicator for an appropriate level of expressivity, we examine the world of non-lazy sequences, i.e., sequences that can be fully represented in memory.

\subsection{Case Study: Strict Sequences}\label{strict_sequences}

Representing sequences in memory can be done in such a natural way that we have never seen any explicit discussion. We shall assume a typical type system with product types (denoted $(S, T)$), sum types (denoted $S + T$), and homogeneous array types (denoted ($[T]$)).

Let $T$ be a type, then $T$ is also the type of a sequence of exactly one item of type $T$. Now, let $S$ and $T$ be types of sequences. Then $(S, T)$ denotes the concatenations of sequences of type $S$ and sequences of type $T$, $S + T$ denotes the sequences either of type $S$ or $T$, and $[T]$ denotes the concatenations of arbitrarily (but finitely) many sequences of type $T$. None of this is particularly surprising, we basically just stated that algebraic data types and array types allow you to lay out data sequentially in memory.

Slightly more interesting is the blatant isomorphism to regular expressions. Each of the ``sequence combinators'' corresponds to an operator to construct regular expressions; the empty type and the unit type correspond to the neutral elements of the choice and concatenation operator respectively.

This is useful for making our expressivity requirement for lazy sequence APIs more precise: if the natural representation of strict sequences admits exactly the regular languages, then the regular languages are also the natural candidate level of expressivity for lazy APIs.

Unlike strict sequences that have to fit into finite memory, lazy sequences can be of infinite length. The natural generalization of the regular languages are the $\omega$-regular languages. Hence, this is the level of expressivity we want to see in lazy APIs.

The strict case also neatly supports the design goals of minimality and symmetry. Removing any combinator leads to a strictly less expressive class of languages, and every operator comes both with a way of building up values and with a way of accessing values.

By generalizing the strict case to the lazy case, we can make our requirement of expressivity more precise, leading us to our final set of requirements: We want APIs for lazily producing or consuming sequences an item at a time, such that there is a one-to-one mapping between API instances and $\omega$-regular languages, no aspect of the APIs can be removed without loosing this one-to-one mapping, and there is full symmetry between consumption and production of a sequence. Still not entirely formal, but close enough to meaningfully evaluate and design APIs.

\subsection{Organization}

TODO

\section{Related Work}\label{related_work}

TODO

Iterees: 
\url{https://link.springer.com/chapter/10.1007/978-3-642-29822-6_15}
\url{https://hackage.haskell.org/package/iterIO-0.2.2/docs/Data-IterIO.html}

session types

pull-stream paper

\url{http://jiangxi.cs.uwm.edu/publication/rebls2020.pdf}

\url{https://arxiv.org/pdf/1612.06668.pdf} (good related work)

\section{Evaluating Abstractions}\label{evaluating_others}

We now start by introducing a notation for API designs. We then express several APIs we encountered in the wild in our notation, in order to build intuition, demonstrate sufficient notational expressivity, and to highlight typical violations of our design goals in popular APIs. We do not aim for an exhaustive survey of APIs, we merely select some examples to illustrate our points.

In the following, we use uppercase letters as type variables. $(S, T)$ denotes the product type of types $S$ and $T$ (intuitively, the cartesian product of $S$ and $T$), and $()$ denotes the unit type (intuitively, the type with only a single value). $S | T$ denotes the sum type of $S$ and $T$ (intuitively, the disjoint union of $S$ and $T$), and $!$ denotes the empty type (intuitively, the type that admits no value). Finally, we write $S \rightarrow T$ for the type of (pure) functions with an argument of type $S$ and a return value of type $T$. Note we take a purely functional approach here: a function does not mutate its argument, it simply produces a new value.

We specify an API as a list of named types (typically functions). Each API can quantify type variables that can be used in its \textit{members}\footnote{More formally, this is a notation for ad-hoc polymorphism like Haskell's type classes, Java's interfaces, or Rust's traits.}. As an example, consider the following API:

\begin{lstlisting}[language=Python]
API Iterator<P, I>
    next: P -> (I, P) | ()
\end{lstlisting}

This pseudo-type fragment states that in order to obtain a concrete \texttt{Iterator}, one needs two types: a type $P$ (\textbf{P}roducer) and a type $I$ (\textbf{I}tem). These types have to be related through existence of a function \texttt{next}, which maps a producer to either an item and and a new producer, or to a value that signifies that no further items can be produced.

To consume this iterator, one would repeatedly call \texttt{next} on the producer returned from the prior call of \texttt{next}, until no further Items are produced.

A concrete example of an iterator are the homogenous arrays of $I$s as producers of $I$s; \texttt{next} returns $()$ for the empty array, otherwise it returns the first item in the array and the array obtained by removing the first item.

This API is completely stateless, we never mutate any $P$. In an imperative programming language, one would typically use a function that takes a reference to a $P$ and returns either an $I$ or $()$, and then makes all implementors pinky-swear to not invoke the function with a $P$ that has returned $()$ previously.

We prefer the purely functional notation, because it can express the pinky-swearing API contract on the type level. But all our designs can easily be translated into an imperative, stateful setting. The other way around, by converting stateful references into input values and output values, we can represent APIs from imperative languages in our notation. For example, this \texttt{Iterator} API captures the semantics of commonly used iterator APIs such as those of Python\footnote{\url{https://wiki.python.org/moin/Iterator}} or Rust\footnote{\url{https://doc.rust-lang.org/std/iter/trait.Iterator.html}}. It handily abstracts over the fact that Rust has actual sum types, whereas Python signals the end of iteration with an exception.

Without devoting too much space to it, we want to point out that even for such a simple special case of sequence processing as iteration --- i.e., synchronous production of finite sequences without buffering or error handling --- there are several, non-isomorphic approaches in the wild. Both Java\footnote{\url{https://docs.oracle.com/javase/8/docs/api/java/util/Iterator.html}} and Javascript\footnote{\url{https://tc39.es/ecma262/multipage/control-abstraction-objects.html\#sec-iterator-interface}} use APIs with slightly different properties; they differ in how early the code interacting with the iterator knows that no further items will be produced.

Given the symmetry between producing and consuming data, the virtual non-existence of (synchronous, non-error-handling) APIs for consuming data step by step is jarring. Java has an \texttt{Appendable} interface\footnote{\url{https://docs.oracle.com/javase/8/docs/api/java/lang/Appendable.html}}, but it is specialized to characters, and has a much less prominent role than the \texttt{Iterator} interface. Clojure complects both production and consumption into a single \texttt{Sequence} interface\footnote{\url{https://clojure.org/reference/sequences\#_the_seq_interface}}. Several languages do give the opposite of iterators a prominent role: for loops that consume an iterator item by item. Baking sequence production via first-class values into a language while turning sequence consumption into a purely syntactic component with no run-time presence massively breaks symmetry from a high level design perspective.

Moving beyond synchronous iterators, \textit{asynchronous} producers --- often called \textit{streams} --- typically come with buffering and error handling. We shall abstract over\footnote{The seasoned Haskell-affectionado will immediately see that parameterizing our presentation over a monad for effectful computation~\cite{wadler1995monads} would restore rigorous reasoning to our handwavy act of abstraction. We posit that to the readers who are already familiar with effect-management through monads, filling in the blanks is an easy exercise. To those readers who are not famliar with this technique --- i.e., the vast majority of practicioners we would like to reach --- obscuring our presentation behind higher-kinded type constructors poses an unnecessary barrier to access.} both buffering and asynchronicity, as they do not influence matters of minimality, symmetry, or expressiveness regarding formal languages. We believe that designing a solid API irrespective of buffering and asynchronicity and then adding them in a way that is idiomatic for the programming language in question leads to clearer designs. In particular, we see no reason why synchronous and asynchronous sequence APIs in the same language should not be completely analogous.

An example where the asynchronous producer API is equivalent to the synchronous iterator API is --- as of writing --- Rust\footnote{\url{https://docs.rs/futures/0.3.30/futures/stream/trait.Stream.html}}. This is rather atypical, because asynchronous APIs, which are often motivated by networking, usually emphasize error handling. In the iterator API, one can use a sum type of actual items and an error type as the type $I$, but on the type level, it remains possible to continue iterating after an error. The API is accurate for recoverable errors only.

A different example is Swift\footnote{\url{https://developer.apple.com/documentation/swift/asyncsequence}}, which superficially appears to offer an equivalent API, but the language-level feature of throwing exceptions allows the ability to express irrecoverable errors\footnote{\url{https://developer.apple.com/documentation/swift/asyncthrowingstream}}. In our notation, the Swift API is:

\begin{lstlisting}[language=Python]
API FallibleIterator<P, I, E>
    next: P -> (I, P) | () | E
\end{lstlisting}

This particular API design violates minimality: removing the option of returning the unit type would leave the degree of expressivity unchanged, since one could always instantiate $E$ as a sum type of the unit type and an actual error type. It might be tempting to argue that the Swift API communicates intent more clearly, and allows for nicer library functions for working with streams. But these conveniences and specializations could just as well be implemented as special cases of the more general, underlying pattern. Rust nicely demonstrates this by offering a host of functions\footnote{\url{https://docs.rs/futures/latest/futures/stream/trait.TryStreamExt.html}} for working with streams whose items are a sum type of actual items and error values. Offering a special case as the most fundamental API, like Swift does, unnecessarily reduces expressivity.

Another school of APIs defines asynchronous producers in terms of all the ways in which one would commonly interact with them: mapping, reducing, piping into a consumer, etc. Examples include Java\footnote{\url{https://docs.oracle.com/javase/8/docs/api/java/util/stream/Stream.html}} or Dart\footnote{\url{https://api.dart.dev/stable/3.3.0/dart-async/Stream-class.html}}. Such designs are not concerned with minimality at all. Our preferred approach is to find the minimal interface that that allows expressing all these higher-level functions on top.

The story for asynchronous \textit{consumers} is usually highly asymmetrical again. Swift, for example, has asynchronous for loops to consume streams. Rust offers a \textit{sink} abstraction\footnote{\url{https://docs.rs/futures/0.3.30/futures/sink/trait.Sink.html}} as the opposite of a stream, but the designs are highly asymmetric --- the sink abstraction requires four functions to the stream abstraction's one function.

% Lack of symmetry in asynchronous sequence APIs is especially surprising, since the typical motivating examples for asynchronous sequences come in pairs: you want to receive data \textit{from} the network \textit{and} write data \textit{to} the network. Unfortunately, APIs for transferring bytes over the network usually deal in \textit{arrays of bytes} and get their own specialized abstractions. A typical example of such \textit{readers} (producers of many bytes simultaneously) and \textit{writers} (consumers of many bytes simultaneously) are the \texttt{Reader}\footnote{\url{https://pkg.go.dev/io\#Reader}} and \texttt{Writer}\footnote{\url{https://pkg.go.dev/io\#Writer}} of the Go language.

% Universality and specialization to obtain iterators.


\section{A Principled Design}\label{main_design}

From this backdrop of rather inconsistent designs, we now present our alternatives. We derive --- in tandem --- APIs for producing and consuming sequences, guided by minimality, symmetry, and expressivity (\cref{derive}). Next, we argue that the designs are indeed sufficiently symmetric and of appropriate expressiveness (\cref{evaluating_ours}) --- if our arguments are not fully formal, they are at least \textit{formalizable}. Finally, we sketch some consequences the designs could have for language-level features such as generators or for loops (\cref{syntax}).

\subsection{Deriving Our Design}\label{derive}

To derive a principled design step by step, we start with simplemost producer API: a producer that emits an infinite stream of items of the same type.

\begin{lstlisting}[language=Python]
API InfiniteProducer<P, I>
    produce: P -> (I, P)
\end{lstlisting}

An iterator, in contrast, expresses a \textit{finite} stream of items, by making the result of a sum type with a unit type otion to signal termination. We can easily abstract over both through a simple realization: we can rewrite the \texttt{produce} function of the \texttt{InfiniteProducer} as a sum with the empty type, without changing the semantics at all (it is impossible to provide an instance of the empty type, the empty type is the neutral element of type sums):

\begin{lstlisting}[language=Python]
API AlsoAnInfiniteProducer<P, I>
    produce: P -> (I, P) | !
\end{lstlisting}

Now, the infinite producer and the finite producer have the exact same form, and we can introduce a type parameter for the summand to express either:

\begin{lstlisting}[language=Python]
API Producer<P, I, F>
    produce: P -> (I, P) | F
\end{lstlisting}

Setting the type parameter \texttt{F} (for \textit{\textbf{f}inal item}) to \texttt{!} or \texttt{()} yields the infinite streams and the finite streams over a single type of items, respectively.

Another natural choice for \texttt{F} are irrecoverable error types; most APIs with this design denote the type parameter as a type of errors explicitly. This denotation obscures how the same abstraction can also represent iterators or infinite streams, however.

Moreover, it obscures that \texttt{F} might be another producer itself, with which to continue production. Through this use of the API, we can effectively concatenate any producer after any finite producer. This usage is the cornerstone of achieving the expressivity of the $\omega$-regular languages, and one we have not encountered in the wild at all.

To give a tangible example of how this degree of expressivity can be useful, consider a networking protocol that proceeds in stages: first a handshake for connection establishment, followed by an exchange of key-value pairs that signify the capabilities of an endpoint, followed by the application-level message exchange. With an API parameterized over arbitrary final values, you can implement each stage in a type-safe way, and then concatenate the stages both in execution and on the type-level. Traditional APIs force programmers to either lump the different kinds of messages (handshake, key-value pairs, application-level) into a single sum type, or to forego helpful typing altogether and operate on the level of bytes.

A symmetric consumer API should be one that can be given either an item of type \texttt{I} --- returning a new consumer value to continue the process --- or a final item of some type \texttt{F} --- without returning a consumer to continue with. Ideally, we should be able to mechanically derrive this API as a dual of the producer API. A tempting option is to ``flip all arrows'' and simply swap argument and return type of the \texttt{produce} function:

\begin{lstlisting}[language=Python]
API Recudorp<P, I, F>
    ecudorp: ((I, P) | F) -> P
\end{lstlisting}

We can clean this up by splitting the function of a sum type argument into two independent functions (both versions are equivalent), and giving more conventional names:

\begin{lstlisting}[language=Python]
API NotQuiteConsumer<C, I, F>
    consume: (I, C) -> C
    create: F -> C
\end{lstlisting}

Unfortunately, this does not give the kind of API we were hoping for. The \texttt{consume} function is appropriate, but the second function is not closing a consumer, but creates a consumer. A straightforward dual construction gives too strong of a reversal to yield an API suitable for practical use.

Instead of a fully dual construction, we instead derive a consumer API in steps analogous to those for deriving the \texttt{Producer} API. We start again with the consumers of an infinite sequence and the consumer of a finite sequence:

\begin{lstlisting}[language=Python]
API InfiniteConsumer<C, I>
    consume: (I, C) -> C

API FiniteConsumer<C, I>
    consume: (I, C) -> C
    close: C -> C
\end{lstlisting}

We can again introduce a type parameter for the final sequence item to unify the APIs; observe how using $!$ or $()$ for the parameter \texttt{F} in the following API yields results isomorphic to the \texttt{InfiniteConsumer} and \texttt{FiniteConsumer} APIs respectively:

\begin{lstlisting}[language=Python]
API Consumer<C, I, F>
    consume: (I, C) -> C
    close: (F, C) -> ()
\end{lstlisting}

This API is fully symmetric to the \texttt{Producer}: the consumer can consume exactly those sequences that a producer can produce. It is rather unusual in that we have never seen an API whose \texttt{close} function takes an argument in the wild.

Another unusual aspect is the inability of a consumer to report errors to its calling code. This is severe enough of a departure from typical APIs that we discuss this in more detail in \cref{communication_flow}. But first, we will argue that these \texttt{Producer} and \texttt{Consumer} APIs indeed fulfil our initial design requirements.

\subsection{Evaluating Our Design}\label{evaluating_ours}

Convincing arguments for the symmetry of the APIs are not immediately apparent; while we derived both APIs throuh analogous steps, they are not immediately dual in any obvious sense, and they even have a different number of functions. The closest we could come to a formal argument is to show that they compose in a satisfying way.

Composing a producer with a consumer amounts to piping the data that the producer produces into the consumer:

\begin{algorithmic}
\Require $P, C, I, F$ are types such that \texttt{Producer<P, I, F>} and \texttt{Consumer<C, I, F>}
\Procedure{pipe}{$p: P$, $c: C$}{$: ()$}
    \Loop
        \State $x \gets \Call{produce}{p}$
        \If{$x$ is of type $F$}
            \State \Call{close}{$x, c$}
            \State \texttt{return} $()$
        \Else
            \State $c \gets \Call{consume}{x.0}$
            \State $p \gets x.1$
        \EndIf
    \EndLoop
\EndProcedure
\end{algorithmic}

Notice that the \texttt{pipe} function returns the unit type, it leaks no information to the outside. More traditional APIs have no way to funnel the final (usually irrecoverable error) value of the producer to the consumer, so the pipe function has to return that value to the outside. Similarly, APIs that allow consumers to emit errors also have to forward such errors from the pipe function.

On a purely abstract level, composing to the unit type evokes the concept of an element and its inverse composing to an identity element. This seems as strong a formal notion of symmetry we can hope for, without \textit{actually} formalizing things.

More concretely, this means that a producer and a consumer together can fully describe a (sub-)program that processes a data stream. While traditional APIs also allow building up programs by combining and modifying producers and consumers, there always has to be ad-hoc glue code for handling errors, and for moving from one stage of processing to the next. Our APIs capture a fuller set of tasks of such programs. In principle, with an expressive library for constructing producers and consumers, it should be possible to describe much wider classes of programs by piping a single producer into a single consumer, with no glue code or ad-hoc error handling. In particular, progressing from one processing stage to the next can be done by having the producer emit a new producer as a final value, and the consumer pipe this value into an inner consumer in its \texttt{close} function.

We can make a similar argument for composing the other way around: it should be possible to create a pair of a consumer and a producer such that the producer produces everything that the consumer consumes, in the same order (an in-memory queue). This is, in some vague sense, the neutral element of transformation steps in a pipeline (we return to this concept in \cref{conducer}). Here again, we see the benefits of the \texttt{close} function taking an argument: we can map this argument directly to the final value to be emitted by \texttt{produce}.

Libraries without this feature usually only offer queues parameterized over a single item type. One common tasks where this becomes unnecessarily restrictive include adding intermediate queues for buffering that can also delay propagating an error to the queue's consumer until all items that were emitted before the error have been consumed. Another usecase is testing: if you want to test a component by replacing its input producer with a stub, you cannot use the normal in-memory queue as a replacement, because it cannot emit final values (i.e., errors, in most libraries) on demand.

Having argued that our design is indeed symmetric in a meaningful way, we turn to the question of expressivity. Our core argument rests on the observation that each \texttt{Producer} (or \texttt{Consumer}) defines a formal language over an alphabet of atomic types. More precisely, a \texttt{Producer<P, I, F>} emits an arbitrary number of repetitions of values of type $I$, followed by a single value of type $F$. In more traditional notation of a language as a set of strings, it denotes the set $\set{I}^{\ast} \circ \set{F}$.

Given this mapping from sequence APIs to languages, which class of languages do our APIs describe? We claim they --- in concert with sums, products, and functions --- describe the union of the regular and the $\omega$-regular languages.

The \textit{$\omega$-regular languages} over $\Sigma$ are the sets of infinite strings over $\Sigma$ that are either a concatenation of infinitely many words from the same regular language\footnote{We assume familiarity with regular languages, for an introduction see~\cite{hopcroft1969formal}, for example. Or do the sensible thing of searching for ``regular language'' on Wikipedia.} over $\Sigma$ (\textit{infinite iteration}), or the concatenation of a regular language and an $\omega$-regular language over $\Sigma$, or a choice between finitely many $\omega$-regular languages over $\Sigma$.

As already argued in \cref{strict_sequences}, sum types and product tyes correspond to choice and concatenation of regular expressions respectively. Unlike the strict case, we cannot rely on homogeneous arrays to act as the counterpart to the Kleene operator, but this appears to be where the \texttt{Producer} API comes in (everything applies analogously for the \texttt{Consumer} API): a \texttt{Producer<P, I, F>} can produce an arbitrary number of repetitions of \texttt{I}s, followed by a single \texttt{F}. In particular, \texttt{Producer<P, I, ()>} corresponds to the Kleene operator, and \texttt{Producer<P, I, !>} corresponds to infinite iteration.

Unfortunately, this simple perspective is not fully accurate. Product types as concatenation are too powerful for us: consider a product $(P_1, P_2)$, where $P_1$ is a \texttt{Producer<P, I, !>}. The corresponding language would be a concatenation with an $\omega$-language on the left, but this is explicitly ruled out by the definition of $\omega$-regular languages. Another facet of the same problem is that the type $(S, T)$ is not one that describes \textit{first} emitting an $S$ and \textit{then} a $T$, as it presents both simultaneously.

To solve this, we can restrict the set of well-formed sequence types we consider to pairs $(S, () \rightarrow T)$ for (sums of) non-repeated types $S$ and arbitrary types $T$, and \texttt{Producer<P, S, T>} for repeated types $S$. This removes the ability to express concatenations with an $\omega$-language as the left operand, and introduces the required indirection to express ``first $S$, then $T$'' (remember that we assume our functions to abstract over effects, so there might well be asynchronicity involved in obtaining the $T$ after processing the $S$).

We shall not dwell on this subtlety any further, because it does not affect our two main points: our API is expressive enough to decribe regular ($\omega$-)regular languages, whereas a more traditional API \textit{without} a dedicated type for the final item is \textit{not} expressive enough, resulting in an unjustified reduction in expressive power compared to representing strict sequences in memory.

\subsection{Communication Flow}\label{communication_flow}

At this point, we claim to have found APIs that satisfy exactly what we set out to achieve: symmetric consumption and production of $\omega$-regular sequences with a minimal interface. Unfortunately, there is still a problem: if we were to use the consumer API to write data to a network, the API would be unable to report any failures. More generally speaking, code interacting with a \textit{producer} can obtain information \textit{from} the producer but cannot pass any information \textit{to} the producer; conversely, code interacting with a \textit{consumer} can pass information \textit{to} the consumer but cannot obtain any information \textit{from} the consumer.

This rigorous a restriction on communication flows evokes design choices such as the unidirectional communication primitives of security-focussed micro-kernels such as seL4~\cite{murray2013sel4}, so there clearly is a place for such constrained APIs. But the consumer API is too constrained for network programming.



To allow for the consumer to communicate back to the code that uses it, we add a new 





\begin{lstlisting}[language=Python]
API ConsumerAttempt<C, I, F, S>
    consume: (I, C) -> C | S
    close: (F, C) -> () | S
\end{lstlisting}
    
\begin{lstlisting}[language=Python]
API Producer<P, I, F, S>
    produce: P -> (I, P) | F
    stop: (P, S) -> ()
\end{lstlisting}

\section{Working With Producers and consumers}

conducer (aka super-coroutine, Inum, generalized anti-pipe); queue, map, encoders and decoders.

\subsection{Language-Level Consequences}\label{syntax}\label{conducer}

pro and con as specialiazations of conducers, and alternatives to generators and for loops respectively.

\subsection{Bulk Processing}

Buffered.

Slices. (should be strict subtypes)

mention vectored io?

\section{Beyond the Basics}\label{fun}

Combinators.

Lengths and limits.

Asynchrony.

Trees. DAGs? Digraphs?

Coroutines/generators generalized.

Turing machines.

Elastic Turing machines.

Outside movement.

from sequences to structured data?

from sequences to sets (should be easier)?

proper duality?

Specalization, but from where? Turing machine? Supercoroutine?

\section{Conclusion}\label{conclusion}

TODO

vision of unified, consistent APIs throughout a full language ecosystem. Getting things right is simpler than getting them wrong.

On a meta note, this essay constitutes evidence that you can share research results with broad applications to a wide range of programming practitioners, without assuming the kind of deep, intuitive familiarity with the Haskell standard library that requires years of practice to obtain. How did that ever become accepted practice in the first place?

\section{Appendix A: Javascript Libraries}\label{wtfjs}

This list of javaScript libraries for working with lazy sequences is intended to demonstrate that there is a clear need for a solid design that people can fall back to rather than reinventing ad-hoc wheels over and over. We list libraries with at least 200 stars on Github, as of February 2024, found by searching Gihub for ``stream'', ``observable'', and ``reactive''.

\begin{itemize}
    \item \url{https://github.com/staltz/xstream}
    \item \url{https://github.com/mafintosh/streamx}
    \item \url{https://github.com/getify/monio}
    \item \url{https://github.com/getify/asynquence}
    \item \url{https://github.com/cyclejs/cyclejs}
    \item \url{https://github.com/winterbe/streamjs}
    \item \url{https://github.com/winterbe/sequency}
    \item \url{https://github.com/pull-stream/pull-stream}
    \item \url{https://github.com/dionyziz/stream.js}
    \item \url{https://github.com/caolan/highland}
    \item \url{https://github.com/kefirjs/kefir}
    \item \url{https://github.com/baconjs/bacon.js}
    \item \url{https://github.com/cujojs/most}
    \item \url{https://github.com/callbag/callbag}
    \item \url{https://github.com/paldepind/flyd}
\end{itemize}
    
The following libraries do not explicitly define \textit{streams}, but they do work with \textit{observables}. Observables are an abstraction for values that (discretely) vary over time. For most intents and purposes, this is isomorphic to the notion of a stream.

\begin{itemize}
    \item \url{https://github.com/reactivex/rxjs}
    \item \url{https://github.com/tc39/proposal-observable}
    \item \url{https://github.com/zenparsing/zen-observable}
    \item \url{https://github.com/vobyjs/oby}
    \item \url{https://github.com/adamhaile/S}
    \item \url{https://github.com/luwes/sinuous}
    \item \url{https://github.com/mobxjs/mobx}
    \item \url{https://github.com/fynyky/reactor.js}
    \item \url{https://github.com/ds300/derivablejs}
    \item \url{https://github.com/elbywan/hyperactiv}
    \item \url{https://github.com/component/reactive}
    \item \url{https://github.com/mattbaker/Reactive.js}
\end{itemize}

These libraries exist in addition to language-level or runtime-level APIs such as the following:

\begin{itemize}
    \item \href{https://nodejs.org/api/stream.html}{Node JS Streams}, and their evolution: \begin{itemize}
        \item \href{https://nodejs.org/docs/v0.1.100/api.html}{streams0}
        \item \href{https://nodejs.org/docs/v0.4.0/api/streams.html}{streams1}
        \item \href{https://nodejs.org/docs/v0.10.0/api/stream.html}{streams2}
        \item \href{https://nodejs.org/docs/v0.11.5/api/stream.html}{streams3}
    \end{itemize}
    \item \href{https://streams.spec.whatwg.org/}{WHATWG Streams}
    \item \href{https://tc39.es/ecma262/multipage/control-abstraction-objects.html#sec-%iteratorprototype%-object}{ECMAScript Iterator}
    \item \href{https://tc39.es/ecma262/multipage/control-abstraction-objects.html#sec-asynciteratorprototype}{ECMAScript AsyncIterator}
\end{itemize}

\bibliographystyle{alphaurl}
\bibliography{main}
\end{document}
